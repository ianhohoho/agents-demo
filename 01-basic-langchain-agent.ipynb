{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6698b4ac",
   "metadata": {},
   "source": [
    "### env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a404c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78538360",
   "metadata": {},
   "source": [
    "### search tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1b60b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "933a80ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fb14df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.invoke('Who is the prime minister of Singapore?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8979327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.pmo.gov.sg/The-Cabinet/Mr-LEE-Hsien-Loong',\n",
       " 'content': \"Biodata\\nCareer\\n2004 -\\nPrime Minister\\nChairman, Research, Innovation and Enterprise Council (RIEC)\\nChairman, Government of Singapore Investment Corporation (2011)\\n2001 - 2007\\nMinister for Finance\\n1998 - 2004\\nChairman, Monetary Authority of Singapore\\n1990 - 2004\\nDeputy Prime Minister\\n1987 - 1992\\nMinister for Trade and Industry\\n1987 - 1990\\nSecond Minister for Defence\\n1984 - 1987\\nMinister of State for Ministry of Trade and Industry &\\nMinistry of Defence\\n2004 -\\nSecretary-General, People's Action Party\\n1992 - 2004\\nFirst Assistant Secretary-General, People's Action Party\\n1989 - 1992\\nSecond Assistant Secretary-General, People's Action Party\\n1986 - 1989\\nMember, Central Executive Committee of the People's Action Party\\n1984 -\\nMember of Parliament\\n(First elected in 1984, and re-elected in 1988, 1991, 1997, 2001, 2006 and 2011)\\n1982 - 1984\\nChief of Staff of the General Staff\\n1983 - 1984\\nDirector of the Joint Operations and Plans Directorate\\n1978 - 1979\\nAttended the US Army Command and General Staff College at Fort Leavenworth, USA\\n1971\\nCompleted Officer Cadet Course at SAFTI and commissioned as 2nd Lieutenant in the SAF\\nAcademic\\n1979 - 1980\\nMason Fellow at the Kennedy School of Government, Harvard University; graduated with a Master's Degree in Public Administration\\n1974\\nUniversity of Cambridge, UK; graduated as a Senior Wrangler in the Mathematics Tripos (equivalent to First Class Honours) and with a Diploma in Computer Science (with Distinction)\\n1971\\nAwarded the SAF Scholarship\\n1970\\nAwarded the President's Scholarship\\n1970\\nNational Junior College\\n1964 - 1969\\nCatholic High School\\n1958 - 1963\\nNanyang Girls' High School (Co-Ed Primary Section)\\n More profiles\\nDeputy Prime Minister and Minister for Finance\\nDeputy Prime Minister and Coordinating Minister for Economic Policies\\nSenior Minister and Coordinating Minister for National Security\\nMinister for Defence\\nMinister for Foreign Affairs\\nMinister for Home Affairs and Minister for Law\\nMinister for Trade and Industry\\nMinister for Transport\\nMinister for Sustainability and the Environment\\nMinister for Education\\nMinister for Social and Family Development and Second Minister for Health\\nMinister for Health\\nMinister for National Development\\nMinister for Communications and Information and Second Minister for Home Affairs\\nMinister, Prime Minister's Office, Second Minister for Finance and Second Minister for National Development\\nMinister, Prime Minister's Office, Second Minister for Education and Second Minister for Foreign Affairs\\nMinister for Culture, Community and Youth and Second Minister for Law\\nMinister for Manpower and Second Minister for Trade and Industry\\nPrime Minister's Office Singapore\\n© 2023 Government of Singapore.\\n You are here\\nMr LEE Hsien Loong\\nMr LEE Hsien Loong, Prime Minister\\nMr Lee Hsien Loong\\xa0has been Singapore’s Prime Minister since 2004.\\n Before becoming Prime Minister, Mr Lee had held various Ministerial appointments, including being Deputy Prime Minister, Minister for Finance, Minister for Trade and Industry and Second Minister for Defence. As Prime Minister, he launched SkillsFuture to support Singaporeans in embracing lifelong learning and skills, and the Smart Nation initiative to use technology to create a future of better living, more opportunities and stronger communities.\\n\"}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca687a7",
   "metadata": {},
   "source": [
    "- langchain is good for these kind of convenient abstractions. easy to experiment with integrations like search APIs.\n",
    "- but you can easily end up in a deep black hole if you try to trace the abstraction. see source code examples [here](https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/tavily_search/tool.html#TavilySearchResults) and [here](https://api.python.langchain.com/en/latest/_modules/langchain_core/tools.html#BaseTool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604743c1",
   "metadata": {},
   "source": [
    "### retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb1e82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://learn.microsoft.com/en-us/azure/search/semantic-search-overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c6f4575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"What semantic ranking can't do is rerun the query over the entire corpus to find semantically relevant results. Semantic ranking reranks the existing result set, consisting of the top 50 results as scored by the default ranking algorithm. Furthermore, semantic ranking can't create new information or strings. Captions and answers are extracted verbatim from your content so if the results don't include answer-like text, the language models won't produce one.\\nAlthough semantic ranking isn't beneficial in every scenario, certain content can benefit significantly from its capabilities. The language models in semantic ranking work best on searchable content that is information-rich and structured as prose. A knowledge base, online documentation, or documents that contain descriptive content see the most gains from semantic ranking capabilities.\", metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'}),\n",
       " Document(page_content='Semantic ranking is both resource and time intensive. In order to complete processing within the expected latency of a query operation, inputs to the semantic ranker are consolidated and reduced so that the reranking step can be completed as quickly as possible.\\nThere are two steps to semantic ranking: summarization and scoring. Outputs consist of rescored results, captions, and answers.\\nHow inputs are collected and summarized\\nIn semantic ranking, the query subsystem passes search results as an input to summarization and ranking models. Because the ranking models have input size constraints and are processing intensive, search results must be sized and structured (summarized) for efficient handling.', metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'}),\n",
       " Document(page_content='How semantic ranker works\\nSemantic ranking feeds a query and results to language understanding models hosted by Microsoft and scans for better matches.\\nThe following illustration explains the concept. Consider the term \"capital\". It has different meanings depending on whether the context is finance, law, geography, or grammar. Through language understanding, the semantic ranker can detect context and promote results that fit query intent.', metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'}),\n",
       " Document(page_content='Here are the capabilities of the semantic reranker.\\n\\n\\n\\nFeature\\nDescription\\n\\n\\n\\n\\nSemantic ranking\\nUses the context or semantic meaning of a query to compute a new relevance score over preranked results.\\n\\n\\nSemantic captions and highlights\\nExtracts verbatim sentences and phrases from a document that best summarize the content, with highlights over key passages for easy scanning. Captions that summarize a result are useful when individual content fields are too dense for the search results page. Highlighted text elevates the most relevant terms and phrases so that users can quickly determine why a match was considered relevant.\\n\\n\\nSemantic answers\\nAn optional and extra substructure returned from a semantic query. It provides a direct answer to a query that looks like a question. It requires that a document has text with the characteristics of an answer.', metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"limitations of semantic ranking?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400aa8a",
   "metadata": {},
   "source": [
    "### tool binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63006d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"azure_ai_search\",\n",
    "    \"Search for information about Azure Semantic Search. For any questions about Azure Semantic Search, you must use this tool!\",\n",
    ")\n",
    "\n",
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9531bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TavilySearchResults()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2102d3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='azure_ai_search', description='Search for information about Azure Semantic Search. For any questions about Azure Semantic Search, you must use this tool!', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x11756cea0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x137e2f3e0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x11756d3a0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x137e2f3e0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251ef0c",
   "metadata": {},
   "source": [
    "- abstractions are good, but you quickly realise that you don't have a good overview of the expected inputs/outputs from each of these tools... hard to control and debug down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27b1eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30dec1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# ummm is this really necessary? example of abstraction that makes you go hmm...\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b4c42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b161d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model_with_tools(message: str, model_with_tools=model_with_tools) -> None:\n",
    "\n",
    "    response = model_with_tools.invoke([HumanMessage(content=message)])\n",
    "\n",
    "    print(f\"ContentString: {response.content}\")\n",
    "    print(f\"ToolCalls: {response.tool_calls}\")\n",
    "    pprint(response.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e48b6e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n",
      "{'additional_kwargs': {},\n",
      " 'content': 'Hello! How can I assist you today?',\n",
      " 'example': False,\n",
      " 'id': 'run-028c9bae-24b8-412b-ba2e-9c0f038346db-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'stop',\n",
      "                       'logprobs': None,\n",
      "                       'model_name': 'gpt-3.5-turbo-0125',\n",
      "                       'system_fingerprint': None,\n",
      "                       'token_usage': {'completion_tokens': 10,\n",
      "                                       'prompt_tokens': 130,\n",
      "                                       'total_tokens': 140}},\n",
      " 'tool_calls': [],\n",
      " 'type': 'ai'}\n"
     ]
    }
   ],
   "source": [
    "invoke_model_with_tools('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eefbafc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Singapore'}, 'id': 'call_JbtqL7RXXVA6XutzIOcvST27'}]\n",
      "{'additional_kwargs': {'tool_calls': [{'function': {'arguments': '{\"query\":\"weather '\n",
      "                                                                 'in '\n",
      "                                                                 'Singapore\"}',\n",
      "                                                    'name': 'tavily_search_results_json'},\n",
      "                                       'id': 'call_JbtqL7RXXVA6XutzIOcvST27',\n",
      "                                       'type': 'function'}]},\n",
      " 'content': '',\n",
      " 'example': False,\n",
      " 'id': 'run-e4054405-1f74-4a7e-b3c1-9dba94091e66-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'tool_calls',\n",
      "                       'logprobs': None,\n",
      "                       'model_name': 'gpt-3.5-turbo-0125',\n",
      "                       'system_fingerprint': None,\n",
      "                       'token_usage': {'completion_tokens': 20,\n",
      "                                       'prompt_tokens': 135,\n",
      "                                       'total_tokens': 155}},\n",
      " 'tool_calls': [{'args': {'query': 'weather in Singapore'},\n",
      "                 'id': 'call_JbtqL7RXXVA6XutzIOcvST27',\n",
      "                 'name': 'tavily_search_results_json'}],\n",
      " 'type': 'ai'}\n"
     ]
    }
   ],
   "source": [
    "invoke_model_with_tools(\"what's the weather in singapore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ae510",
   "metadata": {},
   "source": [
    "#### what would this have looked like if you used the api directly - [taken from openai docs directly]\n",
    "```python\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "print(run_conversation())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85e03e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_agent(message):\n",
    "    \n",
    "    from langgraph.prebuilt import chat_agent_executor\n",
    "\n",
    "    agent_executor = chat_agent_executor.create_tool_calling_executor(model, tools)\n",
    "    \n",
    "    response = agent_executor.invoke({\"messages\": [HumanMessage(content=message)]})\n",
    "    \n",
    "    return response['messages']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728a530",
   "metadata": {},
   "source": [
    "okay let's go down the rabbit [hole](https://github.com/langchain-ai/langgraph/blob/main/langgraph/prebuilt/chat_agent_executor.py) -- now we enter the graph frameworks (see `create_tool_calling_executor`) -- see bottom of the notebook for the src code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "710b1fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi', id='192cbcd1-fc45-4b22-9a58-b2755ad91b19'),\n",
       " AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 130, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-de35f43c-5673-4b49-9c6e-d4491b63139b-0')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_agent('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20bf4ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what are the limitations of azure semantic search', id='20006eca-4758-44e8-a422-7eff2b66550e'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_utMNjad8h4hd04ycdqPLH4E5', 'function': {'arguments': '{\"query\":\"limitations of Azure Semantic Search\"}', 'name': 'azure_ai_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 137, 'total_tokens': 156}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-073da0cb-db98-45d8-8318-262759e09f5b-0', tool_calls=[{'name': 'azure_ai_search', 'args': {'query': 'limitations of Azure Semantic Search'}, 'id': 'call_utMNjad8h4hd04ycdqPLH4E5'}]),\n",
       " ToolMessage(content=\"The underlying technology is from Bing and Microsoft Research, and integrated into the Azure AI Search infrastructure as an add-on feature. For more information about the research and AI investments backing semantic ranking, see How AI from Bing is powering Azure AI Search (Microsoft Research Blog).\\nThe following video provides an overview of the capabilities.\\n\\nAvailability and pricing\\nSemantic ranker is available on search services at the Basic and higher tiers, subject to regional availability.\\nWhen you enable semantic ranker, choose a pricing plan for the feature:\\n\\nAt lower query volumes (under 1000 monthly), semantic ranking is free.\\nAt higher query volumes, choose the standard pricing plan.\\n\\nThe Azure AI Search pricing page shows you the billing rate for different currencies and intervals.\\nCharges for semantic ranking are levied when query requests include queryType=semantic and the search string isn't empty (for example, search=pet friendly hotels in New York). If your search string is empty (search=*), you aren't charged, even if the queryType is set to semantic.\\nSee also\\n\\nEnable semantic ranking\\nConfigure semantic ranking\\nBlog: Outperforming vector search with hybrid retrieval and ranking capabilities\\n\\n\\n\\n\\n\\n\\n\\nFeedback\\n\\nEdit\\n\\nShare via\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nx.com\\n\\n\\n\\n\\n\\nLinkedIn\\n\\n\\n\\n\\n\\nEmail\\n\\n\\n\\n\\n\\nPrint\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of contents\\n\\nSemantic ranking in Azure AI Search\\n\\nArticle02/08/2024\\n\\n6 contributors\\n\\n\\n\\n\\n\\n\\n\\nFeedback\\n\\n\\n\\nIn this article\\nIn Azure AI Search, semantic ranking measurably improves search relevance by using language understanding to rerank search results. This article is a high-level introduction. The section at the end covers availability and pricing.\\nSemantic ranker is a premium feature, billed by usage. We recommend this article for background, but if you'd rather get started, follow these steps:\\n\\n\\nCheck regional availability\\nSign in to Azure portal to verify your search service is Basic or higher\\nEnable semantic ranking and choose a pricing plan\\nSet up a semantic configuration in a search index\\nSet up queries to return semantic captions and highlights\\nOptionally, return semantic answers\\n\\nSemantic ranking - Azure AI Search | Microsoft Learn\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\nThis browser is no longer supported.\\nUpgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.\\n\\nDownload Microsoft Edge\\nMore info about Internet Explorer and Microsoft Edge\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\nExit focus mode\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRead in English\\n\\n\\n\\n\\nSave\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of contents\\n\\n\\n\\nRead in English\\n\\n\\n\\n\\nSave\\n\\n\\n\\n\\n\\nAdd to Plan\\n\\n\\n\\n\\nEdit\\n\\nShare via\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nx.com\\n\\n\\n\\n\\n\\nLinkedIn\\n\\n\\n\\n\\n\\nEmail\\n\\n\\n\\n\\n\\nPrint\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTable of contents\\n\\nSemantic ranking in Azure AI Search\\n\\nArticle02/08/2024\\n\\n6 contributors\\n\\n\\n\\n\\n\\n\\n\\nFeedback\", name='azure_ai_search', id='6dcb1e9a-78f9-4bdc-95f3-bef027228f2e', tool_call_id='call_utMNjad8h4hd04ycdqPLH4E5'),\n",
       " AIMessage(content=\"The limitations of Azure Semantic Search include:\\n\\n1. Availability and Pricing: Semantic ranker is available on search services at the Basic and higher tiers, subject to regional availability. There are pricing plans based on query volumes, with charges for semantic ranking when query requests include queryType=semantic.\\n\\n2. Technology Integration: The underlying technology is from Bing and Microsoft Research, integrated into the Azure AI Search infrastructure as an add-on feature.\\n\\n3. Query Volume: Free usage is available for lower query volumes (under 1000 monthly), while standard pricing plans apply for higher query volumes.\\n\\n4. Billing: Charges for semantic ranking are levied when query requests include queryType=semantic and the search string isn't empty. If the search string is empty, there are no charges even with the queryType set to semantic.\\n\\nFor more detailed information, you can refer to the Microsoft Research Blog and the Azure AI Search documentation.\", response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 693, 'total_tokens': 876}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-830dfe4a-d272-40b3-b94a-50ea1c05e2ff-0')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_agent('what are the limitations of azure semantic search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b396fd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is the weather in singapore?', id='171d567b-ea42-4237-966a-040e449a399a'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Z6kHj6O5OJ2p301JCDQ1F7IZ', 'function': {'arguments': '{\"query\":\"weather in Singapore\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 136, 'total_tokens': 156}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-556e493f-5d41-44a2-adf0-e221adf05e31-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Singapore'}, 'id': 'call_Z6kHj6O5OJ2p301JCDQ1F7IZ'}]),\n",
       " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Singapore\\', \\'region\\': \\'\\', \\'country\\': \\'Singapore\\', \\'lat\\': 1.29, \\'lon\\': 103.86, \\'tz_id\\': \\'Asia/Singapore\\', \\'localtime_epoch\\': 1716776135, \\'localtime\\': \\'2024-05-27 10:15\\'}, \\'current\\': {\\'last_updated_epoch\\': 1716776100, \\'last_updated\\': \\'2024-05-27 10:15\\', \\'temp_c\\': 32.0, \\'temp_f\\': 89.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 150, \\'wind_dir\\': \\'SSE\\', \\'pressure_mb\\': 1010.0, \\'pressure_in\\': 29.83, \\'precip_mm\\': 0.01, \\'precip_in\\': 0.0, \\'humidity\\': 71, \\'cloud\\': 75, \\'feelslike_c\\': 43.0, \\'feelslike_f\\': 109.3, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 8.2, \\'gust_kph\\': 13.2}}\"}, {\"url\": \"http://www.weather.gov.sg/weather-fortnightly-outlook/\", \"content\": \"Forecasts\\\\nWorld Forecasts\\\\nMarine Forecasts\\\\nLightning Information\\\\nCurrent Observations\\\\nUltraviolet Index (UVI)\\\\nRain Areas\\\\nHeat Stress\\\\nSatellite Images\\\\nAstronomical Data and Tides\\\\nHeavy Rain Warning\\\\nHaze Information\\\\nTropical Cyclone Information\\\\nRegional Earthquake/Tsunami\\\\nRegional Volcanic Eruptions\\\\nHistorical Daily Records\\\\nHistorical Extremes\\\\nClimate Maps\\\\nClimate Of Singapore\\\\nWorld Climate\\\\nPast Climate Trends\\\\nAnnual Reports\\\\nEl Ni\\\\u00f1o / La Ni\\\\u00f1a Status\\\\nLearn\\\\nAbout\\\\nForecast\\\\nWEATHER OUTLOOK (16 January 2023 \\\\u2013 31 January 2024)\\\\n1\\\\u00a0 \\\\u00a0 \\\\u00a0The prevailing Northeast Monsoon conditions are expected to continue in the second half of January 2024, with winds blowing mainly from the northwest or northeast.\\\\n 4\\\\u00a0 \\\\u00a0 \\\\u00a0For updates of the daily weather forecast, please visit the MSS website (www.weather.gov.sg), NEA website (www.nea.gov.sg), or download the myENV app.\\\\nREVIEW OF THE PAST TWO WEEKS (1 \\\\u2013 15 January 2024)\\\\n5\\\\u00a0 \\\\u00a0 \\\\u00a0Northeast Monsoon conditions prevailed over Singapore and the surrounding region in the first half of January 2024 and the winds blew from the northwest or northeast.\\\\n The daily total rainfall of 121.0 mm recorded at Pulau Tekong that day was the highest rainfall recorded for the first half of January 2024.\\\\n Overall, the rainfall for the second half of January 2024 is expected to be above average over most parts of the island.\\\\n For the rest of the fortnight, the daily maximum temperatures are expected to range between 32 degrees Celsius and 33 degrees Celsius on most days.\\\\n\"}, {\"url\": \"https://www.accuweather.com/en/sg/singapore/300597/may-weather/300597\", \"content\": \"Get the monthly weather forecast for Singapore, Central Singapore, Singapore, including daily high/low, historical averages, to help you plan ahead.\"}, {\"url\": \"https://world-weather.info/forecast/singapore/singapore/27-may/\", \"content\": \"Weather in Singapore, May 27. Weather Forecast for May 27 in Singapore, - temperature, wind, atmospheric pressure, humidity and precipitations. Detailed hourly weather chart. May 25 May 26 Select date: May 28 May 29. May 27, 2024 . Weather Forecast is not ready yet. May 27, 2023 : Atmospheric conditions and temperature \\\\u00b0F: RealFeel \\\\u00b0F ...\"}, {\"url\": \"https://www.weather25.com/asia/singapore?page=month&month=May\", \"content\": \"The temperatures in Singapore during May are extremely high, between 27\\\\u00b0C and hot as 32\\\\u00b0C, drinking water regularly is advisable. There\\'s going to be many days of rain during the month of May in Singapore. Singapore should expect an average of 15 to 22 days of rain, so be sure to bring along a waterproof jacket to stay dry this month!\"}]', name='tavily_search_results_json', id='307e96cc-ad00-450c-ab1b-ea362d668031', tool_call_id='call_Z6kHj6O5OJ2p301JCDQ1F7IZ'),\n",
       " AIMessage(content='The current weather in Singapore is as follows:\\n- Temperature: 32.0°C (89.6°F)\\n- Condition: Partly cloudy\\n- Wind: 5.6 mph (9.0 km/h) from SSE\\n- Humidity: 71%\\n- Feels like: 43.0°C (109.3°F)\\n- Visibility: 10.0 km\\n- UV Index: 6.0\\n\\nFor more detailed weather information, you can visit the [Weather API](https://www.weatherapi.com/).', response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 1231, 'total_tokens': 1343}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c4132115-c42a-40f2-bda5-91bf6145d7f5-0')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_agent('what is the weather in singapore?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9971ac",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define a new graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Define the two nodes we will cycle between\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model, acall_model))\n",
    "    workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "    # Set the entrypoint as `agent`\n",
    "    # This means that this node is the first one called\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "\n",
    "    # We now add a conditional edge\n",
    "    workflow.add_conditional_edges(\n",
    "        # First, we define the start node. We use `agent`.\n",
    "        # This means these are the edges taken after the `agent` node is called.\n",
    "        \"agent\",\n",
    "        # Next, we pass in the function that will determine which node is called next.\n",
    "        should_continue,\n",
    "        # Finally we pass in a mapping.\n",
    "        # The keys are strings, and the values are other nodes.\n",
    "        # END is a special node marking that the graph should finish.\n",
    "        # What will happen is we will call `should_continue`, and then the output of that\n",
    "        # will be matched against the keys in this mapping.\n",
    "        # Based on which one it matches, that node will then be called.\n",
    "        {\n",
    "            # If `tools`, then we call the tool node.\n",
    "            \"continue\": \"tools\",\n",
    "            # Otherwise we finish.\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # We now add a normal edge from `tools` to `agent`.\n",
    "    # This means that after `tools` is called, `agent` node is called next.\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    # Finally, we compile it!\n",
    "    # This compiles it into a LangChain Runnable,\n",
    "    # meaning you can use it as you would any other runnable\n",
    "    return workflow.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        interrupt_before=interrupt_before,\n",
    "        interrupt_after=interrupt_after,\n",
    "        debug=debug,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e4949",
   "metadata": {},
   "source": [
    "See [langsmith](https://smith.langchain.com) also -- in my opinion, just a toy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-demo-env",
   "language": "python",
   "name": "agents-demo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
