{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50967fcb-003d-4840-ba3d-98a56ff07d7d",
   "metadata": {},
   "source": [
    "## key takeaway\n",
    "- graphs as mental model for agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59193a59",
   "metadata": {},
   "source": [
    "### env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20154874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978b296",
   "metadata": {},
   "source": [
    "### search tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "073a6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "025ac97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5591d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.invoke('Who is the prime minister of Singapore?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c1a81f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.pmo.gov.sg/The-Cabinet/Mr-LEE-Hsien-Loong',\n",
       " 'content': \"Biodata\\nCareer\\n2004 -\\nPrime Minister\\nChairman, Research, Innovation and Enterprise Council (RIEC)\\nChairman, Government of Singapore Investment Corporation (2011)\\n2001 - 2007\\nMinister for Finance\\n1998 - 2004\\nChairman, Monetary Authority of Singapore\\n1990 - 2004\\nDeputy Prime Minister\\n1987 - 1992\\nMinister for Trade and Industry\\n1987 - 1990\\nSecond Minister for Defence\\n1984 - 1987\\nMinister of State for Ministry of Trade and Industry &\\nMinistry of Defence\\n2004 -\\nSecretary-General, People's Action Party\\n1992 - 2004\\nFirst Assistant Secretary-General, People's Action Party\\n1989 - 1992\\nSecond Assistant Secretary-General, People's Action Party\\n1986 - 1989\\nMember, Central Executive Committee of the People's Action Party\\n1984 -\\nMember of Parliament\\n(First elected in 1984, and re-elected in 1988, 1991, 1997, 2001, 2006 and 2011)\\n1982 - 1984\\nChief of Staff of the General Staff\\n1983 - 1984\\nDirector of the Joint Operations and Plans Directorate\\n1978 - 1979\\nAttended the US Army Command and General Staff College at Fort Leavenworth, USA\\n1971\\nCompleted Officer Cadet Course at SAFTI and commissioned as 2nd Lieutenant in the SAF\\nAcademic\\n1979 - 1980\\nMason Fellow at the Kennedy School of Government, Harvard University; graduated with a Master's Degree in Public Administration\\n1974\\nUniversity of Cambridge, UK; graduated as a Senior Wrangler in the Mathematics Tripos (equivalent to First Class Honours) and with a Diploma in Computer Science (with Distinction)\\n1971\\nAwarded the SAF Scholarship\\n1970\\nAwarded the President's Scholarship\\n1970\\nNational Junior College\\n1964 - 1969\\nCatholic High School\\n1958 - 1963\\nNanyang Girls' High School (Co-Ed Primary Section)\\n More profiles\\nDeputy Prime Minister and Minister for Finance\\nDeputy Prime Minister and Coordinating Minister for Economic Policies\\nSenior Minister and Coordinating Minister for National Security\\nMinister for Defence\\nMinister for Foreign Affairs\\nMinister for Home Affairs and Minister for Law\\nMinister for Trade and Industry\\nMinister for Transport\\nMinister for Sustainability and the Environment\\nMinister for Education\\nMinister for Social and Family Development and Second Minister for Health\\nMinister for Health\\nMinister for National Development\\nMinister for Communications and Information and Second Minister for Home Affairs\\nMinister, Prime Minister's Office, Second Minister for Finance and Second Minister for National Development\\nMinister, Prime Minister's Office, Second Minister for Education and Second Minister for Foreign Affairs\\nMinister for Culture, Community and Youth and Second Minister for Law\\nMinister for Manpower and Second Minister for Trade and Industry\\nPrime Minister's Office Singapore\\n© 2023 Government of Singapore.\\n You are here\\nMr LEE Hsien Loong\\nMr LEE Hsien Loong, Prime Minister\\nMr Lee Hsien Loong\\xa0has been Singapore’s Prime Minister since 2004.\\n Before becoming Prime Minister, Mr Lee had held various Ministerial appointments, including being Deputy Prime Minister, Minister for Finance, Minister for Trade and Industry and Second Minister for Defence. As Prime Minister, he launched SkillsFuture to support Singaporeans in embracing lifelong learning and skills, and the Smart Nation initiative to use technology to create a future of better living, more opportunities and stronger communities.\\n\"}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4c211",
   "metadata": {},
   "source": [
    "- langchain is good for these kind of convenient abstractions. easy to experiment with integrations like search APIs.\n",
    "- but you can easily end up in a deep black hole if you try to trace the abstraction. see source code examples [here](https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/tavily_search/tool.html#TavilySearchResults) and [here](https://api.python.langchain.com/en/latest/_modules/langchain_core/tools.html#BaseTool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751684a",
   "metadata": {},
   "source": [
    "### retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6105c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://learn.microsoft.com/en-us/azure/search/semantic-search-overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650af1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"What semantic ranking can't do is rerun the query over the entire corpus to find semantically relevant results. Semantic ranking reranks the existing result set, consisting of the top 50 results as scored by the default ranking algorithm. Furthermore, semantic ranking can't create new information or strings. Captions and answers are extracted verbatim from your content so if the results don't include answer-like text, the language models won't produce one.\\nAlthough semantic ranking isn't beneficial in every scenario, certain content can benefit significantly from its capabilities. The language models in semantic ranking work best on searchable content that is information-rich and structured as prose. A knowledge base, online documentation, or documents that contain descriptive content see the most gains from semantic ranking capabilities.\", metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'}),\n",
       " Document(page_content='Semantic ranking is both resource and time intensive. In order to complete processing within the expected latency of a query operation, inputs to the semantic ranker are consolidated and reduced so that the reranking step can be completed as quickly as possible.\\nThere are two steps to semantic ranking: summarization and scoring. Outputs consist of rescored results, captions, and answers.\\nHow inputs are collected and summarized\\nIn semantic ranking, the query subsystem passes search results as an input to summarization and ranking models. Because the ranking models have input size constraints and are processing intensive, search results must be sized and structured (summarized) for efficient handling.', metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'}),\n",
       " Document(page_content='How semantic ranker works\\nSemantic ranking feeds a query and results to language understanding models hosted by Microsoft and scans for better matches.\\nThe following illustration explains the concept. Consider the term \"capital\". It has different meanings depending on whether the context is finance, law, geography, or grammar. Through language understanding, the semantic ranker can detect context and promote results that fit query intent.', metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'}),\n",
       " Document(page_content='Here are the capabilities of the semantic reranker.\\n\\n\\n\\nFeature\\nDescription\\n\\n\\n\\n\\nSemantic ranking\\nUses the context or semantic meaning of a query to compute a new relevance score over preranked results.\\n\\n\\nSemantic captions and highlights\\nExtracts verbatim sentences and phrases from a document that best summarize the content, with highlights over key passages for easy scanning. Captions that summarize a result are useful when individual content fields are too dense for the search results page. Highlighted text elevates the most relevant terms and phrases so that users can quickly determine why a match was considered relevant.\\n\\n\\nSemantic answers\\nAn optional and extra substructure returned from a semantic query. It provides a direct answer to a query that looks like a question. It requires that a document has text with the characteristics of an answer.', metadata={'source': 'https://learn.microsoft.com/en-us/azure/search/semantic-search-overview', 'title': 'Semantic ranking - Azure AI Search | Microsoft Learn', 'description': 'Learn how Azure AI Search uses deep learning semantic ranking models from Bing to make search results more intuitive.', 'language': 'en-us'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"limitations of semantic ranking?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424f341",
   "metadata": {},
   "source": [
    "### tool binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "200b9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"azure_ai_search\",\n",
    "    \"Search for information about Azure Semantic Search. For any questions about Azure Semantic Search, you must use this tool!\",\n",
    ")\n",
    "\n",
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc90e7",
   "metadata": {},
   "source": [
    "- abstractions are good, but you quickly realise that you don't have a good overview of the expected inputs/outputs from each of these tools... hard to control and debug down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac230e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a903ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# ummm is this really necessary? example of abstraction that makes you go hmm...\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "501fda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6796c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d475d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model_with_tools(message: str, model_with_tools=model_with_tools) -> None:\n",
    "\n",
    "    response = model_with_tools.invoke([HumanMessage(content=message)])\n",
    "\n",
    "    print(f\"ContentString: {response.content}\")\n",
    "    print(f\"ToolCalls: {response.tool_calls}\")\n",
    "    pprint(response.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15325ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n",
      "{'additional_kwargs': {},\n",
      " 'content': 'Hello! How can I assist you today?',\n",
      " 'example': False,\n",
      " 'id': 'run-76868228-568a-4dc8-8bbc-ada63d6e80e0-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'stop',\n",
      "                       'logprobs': None,\n",
      "                       'model_name': 'gpt-3.5-turbo-0125',\n",
      "                       'system_fingerprint': None,\n",
      "                       'token_usage': {'completion_tokens': 10,\n",
      "                                       'prompt_tokens': 130,\n",
      "                                       'total_tokens': 140}},\n",
      " 'tool_calls': [],\n",
      " 'type': 'ai'}\n"
     ]
    }
   ],
   "source": [
    "invoke_model_with_tools('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1194bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Singapore'}, 'id': 'call_5agZy6GguC2KoM7PVFVi2XQh'}]\n",
      "{'additional_kwargs': {'tool_calls': [{'function': {'arguments': '{\"query\":\"weather '\n",
      "                                                                 'in '\n",
      "                                                                 'Singapore\"}',\n",
      "                                                    'name': 'tavily_search_results_json'},\n",
      "                                       'id': 'call_5agZy6GguC2KoM7PVFVi2XQh',\n",
      "                                       'type': 'function'}]},\n",
      " 'content': '',\n",
      " 'example': False,\n",
      " 'id': 'run-2c2294ab-67a7-4997-a59e-9c17394b1faf-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'tool_calls',\n",
      "                       'logprobs': None,\n",
      "                       'model_name': 'gpt-3.5-turbo-0125',\n",
      "                       'system_fingerprint': None,\n",
      "                       'token_usage': {'completion_tokens': 20,\n",
      "                                       'prompt_tokens': 135,\n",
      "                                       'total_tokens': 155}},\n",
      " 'tool_calls': [{'args': {'query': 'weather in Singapore'},\n",
      "                 'id': 'call_5agZy6GguC2KoM7PVFVi2XQh',\n",
      "                 'name': 'tavily_search_results_json'}],\n",
      " 'type': 'ai'}\n"
     ]
    }
   ],
   "source": [
    "invoke_model_with_tools(\"what's the weather in singapore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e6598",
   "metadata": {},
   "source": [
    "#### what would this have looked like if you used the api directly - [taken from openai docs directly]\n",
    "```python\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "print(run_conversation())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cc4b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_agent(message):\n",
    "    \n",
    "    from langgraph.prebuilt import chat_agent_executor\n",
    "\n",
    "    agent_executor = chat_agent_executor.create_tool_calling_executor(model, tools)\n",
    "    \n",
    "    response = agent_executor.invoke({\"messages\": [HumanMessage(content=message)]})\n",
    "    \n",
    "    return response['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d7765",
   "metadata": {},
   "source": [
    "okay let's go down the rabbit [hole](https://github.com/langchain-ai/langgraph/blob/main/langgraph/prebuilt/chat_agent_executor.py) -- now we enter the graph frameworks (see `create_tool_calling_executor`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b88f7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi', id='4cb04639-616f-452b-b93e-287c56d19420'),\n",
       " AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 130, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-75f31d16-6eea-42b8-af2e-30256aa3f7c2-0')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_agent('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ad28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = invoke_agent('what are the limitations of azure semantic search')\n",
    "print(result[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67924f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wei Boon Goh is the Chief Executive at the Centre for Strategic Infocomm Technologies (CSIT). He will be appointed as the Chief Executive (CE) of the Government Technology Agency (GovTech) with effect from 1 June 2023, succeeding Mr. Kok Ping Soon. Wei Boon Goh has a background in technology and leadership. You can find more information about him on his [LinkedIn profile](https://sg.linkedin.com/in/weiboon).\n"
     ]
    }
   ],
   "source": [
    "result = invoke_agent('who is wei boon goh')\n",
    "print(result[-1].content)\n",
    "\n",
    "# oops outdated information!\n",
    "# btw for many search apis nowadays, you can filter for published date to overcome this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc2800",
   "metadata": {},
   "source": [
    "See [langsmith](https://smith.langchain.com) also -- just a toy really"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-demo-env",
   "language": "python",
   "name": "agents-demo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
